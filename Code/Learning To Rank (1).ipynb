{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba0697fe-0e2b-4098-8250-64c3aa6f918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c240801-cf54-442e-aca7-805faee9a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookSearchEngine:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Inisialisasi Search Engine dengan path dataset\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.df = None\n",
    "        self.tfidf_vectorizer = None\n",
    "        self.tfidf_matrix = None\n",
    "        self.bm25_vectorizer = None\n",
    "        self.bm25_matrix = None\n",
    "        self.learning_model = None\n",
    "        self.processed_texts = None\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Load dan preprocessing data dari CSV\n",
    "        \"\"\"\n",
    "        print(\"Loading data...\")\n",
    "        self.df = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Cleaning data\n",
    "        self.df = self.df.dropna(subset=['Book-Title', 'Book-Author', 'description'])\n",
    "        \n",
    "        # Combine text fields untuk search\n",
    "        self.df['combined_text'] = (\n",
    "            self.df['Book-Title'].fillna('') + ' ' + \n",
    "            self.df['Book-Author'].fillna('') + ' ' + \n",
    "            self.df['description'].fillna('')\n",
    "        )\n",
    "        \n",
    "        # Preprocessing text\n",
    "        self.processed_texts = [self.preprocess_text(text) for text in self.df['combined_text']]\n",
    "        \n",
    "        print(f\"Data loaded: {len(self.df)} books\")\n",
    "        \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocessing teks: lowercase, remove punctuation, dll\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = str(text).lower()\n",
    "        \n",
    "        # Remove punctuation\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        \n",
    "        # Remove extra whitespaces\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def build_tfidf_index(self):\n",
    "        \"\"\"\n",
    "        Build TF-IDF index\n",
    "        \"\"\"\n",
    "        print(\"Building TF-IDF index...\")\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(\n",
    "            max_features=10000,\n",
    "            stop_words='english',\n",
    "            ngram_range=(1, 2)\n",
    "        )\n",
    "        \n",
    "        self.tfidf_matrix = self.tfidf_vectorizer.fit_transform(self.processed_texts)\n",
    "        \n",
    "    def calculate_bm25_scores(self, query, k1=1.5, b=0.75):\n",
    "        \"\"\"\n",
    "        Calculate BM25 scores untuk query\n",
    "        \"\"\"\n",
    "        query_terms = self.preprocess_text(query).split()\n",
    "        \n",
    "        # Document frequencies\n",
    "        doc_freqs = {}\n",
    "        for term in query_terms:\n",
    "            doc_freqs[term] = sum(1 for doc in self.processed_texts if term in doc)\n",
    "        \n",
    "        # Average document length\n",
    "        avg_doc_len = np.mean([len(doc.split()) for doc in self.processed_texts])\n",
    "        \n",
    "        scores = []\n",
    "        N = len(self.processed_texts)\n",
    "        \n",
    "        for doc in self.processed_texts:\n",
    "            doc_terms = doc.split()\n",
    "            doc_len = len(doc_terms)\n",
    "            doc_term_freq = Counter(doc_terms)\n",
    "            \n",
    "            score = 0\n",
    "            for term in query_terms:\n",
    "                if term in doc_term_freq:\n",
    "                    tf = doc_term_freq[term]\n",
    "                    df = doc_freqs.get(term, 0)\n",
    "                    if df > 0:\n",
    "                        idf = math.log((N - df + 0.5) / (df + 0.5))\n",
    "                        score += idf * (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * doc_len / avg_doc_len))\n",
    "            \n",
    "            scores.append(score)\n",
    "        \n",
    "        return np.array(scores)\n",
    "    \n",
    "    def extract_features(self, query):\n",
    "        \"\"\"\n",
    "        Extract features untuk Learning to Rank\n",
    "        \"\"\"\n",
    "        # TF-IDF similarity\n",
    "        query_processed = self.preprocess_text(query)\n",
    "        query_tfidf = self.tfidf_vectorizer.transform([query_processed])\n",
    "        tfidf_scores = cosine_similarity(query_tfidf, self.tfidf_matrix).flatten()\n",
    "        \n",
    "        # BM25 scores\n",
    "        bm25_scores = self.calculate_bm25_scores(query)\n",
    "        \n",
    "        # Additional features\n",
    "        query_terms = query_processed.split()\n",
    "        \n",
    "        # Exact title match\n",
    "        title_exact_match = [1 if query.lower() in title.lower() else 0 \n",
    "                           for title in self.df['Book-Title']]\n",
    "        \n",
    "        # Author match\n",
    "        author_match = [1 if any(term in author.lower() for term in query_terms) else 0\n",
    "                for author in self.df['Book-Author'].fillna('')]\n",
    "\n",
    "        \n",
    "        # Title term count\n",
    "        title_term_count = [sum(1 for term in query_terms if term in title.lower()) \n",
    "                           for title in self.df['Book-Title']]\n",
    "        \n",
    "        # Combine features\n",
    "        features = np.column_stack([\n",
    "            tfidf_scores,\n",
    "            bm25_scores,\n",
    "            title_exact_match,\n",
    "            author_match,\n",
    "            title_term_count\n",
    "        ])\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def generate_synthetic_relevance_scores(self, query):\n",
    "        \"\"\"\n",
    "        Generate synthetic relevance scores untuk training\n",
    "        (Dalam implementasi nyata, ini akan berupa human judgments)\n",
    "        \"\"\"\n",
    "        features = self.extract_features(query)\n",
    "        \n",
    "        # Simple heuristic untuk synthetic scores\n",
    "        tfidf_scores = features[:, 0]\n",
    "        title_match = features[:, 2]\n",
    "        author_match = features[:, 3]\n",
    "        \n",
    "        # Weighted combination\n",
    "        relevance_scores = (\n",
    "            0.4 * tfidf_scores + \n",
    "            0.3 * title_match + \n",
    "            0.2 * author_match + \n",
    "            0.1 * features[:, 4]  # title term count\n",
    "        )\n",
    "        \n",
    "        # Normalize to 0-3 scale (0: not relevant, 3: highly relevant)\n",
    "        if relevance_scores.max() > relevance_scores.min():\n",
    "            relevance_scores = (relevance_scores - relevance_scores.min()) / (relevance_scores.max() - relevance_scores.min())\n",
    "            relevance_scores = (relevance_scores * 3).round().astype(int)\n",
    "        else:\n",
    "            relevance_scores = np.zeros(len(relevance_scores), dtype=int)\n",
    "        \n",
    "        return relevance_scores\n",
    "    \n",
    "    def train_learning_to_rank_model(self, sample_queries=None):\n",
    "        \"\"\"\n",
    "        Train Learning to Rank model\n",
    "        \"\"\"\n",
    "        print(\"Training Learning to Rank model...\")\n",
    "        \n",
    "        if sample_queries is None:\n",
    "            # Generate sample queries from book titles and authors\n",
    "            sample_queries = []\n",
    "            for i in range(min(100, len(self.df))):  # Limit untuk efisiensi\n",
    "                title = str(self.df.iloc[i]['Book-Title'])\n",
    "                title_words = title.split()[:2]  # Ambil 2 kata pertama judul\n",
    "                if len(title_words) > 0:\n",
    "                    sample_queries.append(' '.join(title_words))\n",
    "                \n",
    "                author = str(self.df.iloc[i]['Book-Author'])\n",
    "                author_words = author.split()[:1]  # Ambil 1 kata author\n",
    "                if len(author_words) > 0:\n",
    "                    sample_queries.append(author_words[0])\n",
    "        \n",
    "        # Collect training data\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        \n",
    "        for query in sample_queries[:50]:  # Limit untuk efisiensi\n",
    "            try:\n",
    "                features = self.extract_features(query)\n",
    "                relevance_scores = self.generate_synthetic_relevance_scores(query)\n",
    "                \n",
    "                X_train.extend(features)\n",
    "                y_train.extend(relevance_scores)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing query '{query}': {e}\")\n",
    "                continue\n",
    "        \n",
    "        if len(X_train) > 0:\n",
    "            X_train = np.array(X_train)\n",
    "            y_train = np.array(y_train)\n",
    "            \n",
    "            # Train model\n",
    "            self.learning_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "            self.learning_model.fit(X_train, y_train)\n",
    "            \n",
    "            print(\"Learning to Rank model trained!\")\n",
    "        else:\n",
    "            print(\"No training data available. Using TF-IDF fallback.\")\n",
    "    \n",
    "    def search(self, query, top_k=10):\n",
    "        \"\"\"\n",
    "        Search dengan Learning to Rank\n",
    "        \"\"\"\n",
    "        if self.learning_model is None:\n",
    "            # Fallback ke TF-IDF jika model belum ditraining\n",
    "            return self.search_tfidf(query, top_k)\n",
    "        \n",
    "        try:\n",
    "            # Extract features\n",
    "            features = self.extract_features(query)\n",
    "            \n",
    "            # Predict relevance scores\n",
    "            relevance_scores = self.learning_model.predict(features)\n",
    "            \n",
    "            # Get top-k results\n",
    "            top_indices = np.argsort(relevance_scores)[::-1][:top_k]\n",
    "            \n",
    "            results = []\n",
    "            for idx in top_indices:\n",
    "                results.append({\n",
    "                    'rank': len(results) + 1,\n",
    "                    'score': relevance_scores[idx],\n",
    "                    'title': self.df.iloc[idx]['Book-Title'],\n",
    "                    'author': self.df.iloc[idx]['Book-Author'],\n",
    "                    'description': str(self.df.iloc[idx]['description'])[:200] + '...',\n",
    "                    'isbn': self.df.iloc[idx]['ISBN']\n",
    "                })\n",
    "            \n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"Error in search: {e}\")\n",
    "            return self.search_tfidf(query, top_k)\n",
    "    \n",
    "    def search_tfidf(self, query, top_k=10):\n",
    "        \"\"\"\n",
    "        Fallback search menggunakan TF-IDF\n",
    "        \"\"\"\n",
    "        query_processed = self.preprocess_text(query)\n",
    "        query_tfidf = self.tfidf_vectorizer.transform([query_processed])\n",
    "        similarities = cosine_similarity(query_tfidf, self.tfidf_matrix).flatten()\n",
    "        \n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            results.append({\n",
    "                'rank': len(results) + 1,\n",
    "                'score': similarities[idx],\n",
    "                'title': self.df.iloc[idx]['Book-Title'],\n",
    "                'author': self.df.iloc[idx]['Book-Author'],\n",
    "                'description': str(self.df.iloc[idx]['description'])[:200] + '...',\n",
    "                'isbn': self.df.iloc[idx]['ISBN']\n",
    "            })\n",
    "        \n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df927a15-79a7-4d88-bc25-bbd5b2c7caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationMetrics:\n",
    "    \"\"\"\n",
    "    Kelas untuk menghitung metrics evaluasi\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def precision_at_k(relevant_items, retrieved_items, k):\n",
    "        \"\"\"\n",
    "        Precision@K\n",
    "        \"\"\"\n",
    "        if k == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        retrieved_k = retrieved_items[:k]\n",
    "        relevant_retrieved = len([item for item in retrieved_k if item in relevant_items])\n",
    "        \n",
    "        return relevant_retrieved / k\n",
    "    \n",
    "    @staticmethod\n",
    "    def recall_at_k(relevant_items, retrieved_items, k):\n",
    "        \"\"\"\n",
    "        Recall@K\n",
    "        \"\"\"\n",
    "        if len(relevant_items) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        retrieved_k = retrieved_items[:k]\n",
    "        relevant_retrieved = len([item for item in retrieved_k if item in relevant_items])\n",
    "        \n",
    "        return relevant_retrieved / len(relevant_items)\n",
    "    \n",
    "    @staticmethod\n",
    "    def average_precision_at_k(relevant_items, retrieved_items, k):\n",
    "        \"\"\"\n",
    "        Average Precision@K\n",
    "        \"\"\"\n",
    "        if len(relevant_items) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        retrieved_k = retrieved_items[:k]\n",
    "        ap = 0.0\n",
    "        relevant_count = 0\n",
    "        \n",
    "        for i, item in enumerate(retrieved_k):\n",
    "            if item in relevant_items:\n",
    "                relevant_count += 1\n",
    "                precision_at_i = relevant_count / (i + 1)\n",
    "                ap += precision_at_i\n",
    "        \n",
    "        return ap / min(len(relevant_items), k)\n",
    "    \n",
    "    @staticmethod\n",
    "    def ndcg_at_k(relevant_items, retrieved_items, k, relevance_scores=None):\n",
    "        \"\"\"\n",
    "        NDCG@K\n",
    "        \"\"\"\n",
    "        if relevance_scores is None:\n",
    "            # Binary relevance: relevant=1, not relevant=0\n",
    "            relevance_scores = {item: 1 for item in relevant_items}\n",
    "        \n",
    "        retrieved_k = retrieved_items[:k]\n",
    "        \n",
    "        # DCG calculation\n",
    "        dcg = 0.0\n",
    "        for i, item in enumerate(retrieved_k):\n",
    "            if item in relevance_scores:\n",
    "                relevance = relevance_scores[item]\n",
    "                dcg += (2**relevance - 1) / math.log2(i + 2)\n",
    "        \n",
    "        # IDCG calculation\n",
    "        ideal_relevances = sorted([relevance_scores.get(item, 0) for item in relevant_items], reverse=True)[:k]\n",
    "        idcg = 0.0\n",
    "        for i, relevance in enumerate(ideal_relevances):\n",
    "            idcg += (2**relevance - 1) / math.log2(i + 2)\n",
    "        \n",
    "        if idcg == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return dcg / idcg\n",
    "    \n",
    "    @staticmethod\n",
    "    def map_at_k(queries_results, k):\n",
    "        \"\"\"\n",
    "        Mean Average Precision@K\n",
    "        \"\"\"\n",
    "        ap_scores = []\n",
    "        for relevant_items, retrieved_items in queries_results:\n",
    "            ap = EvaluationMetrics.average_precision_at_k(relevant_items, retrieved_items, k)\n",
    "            ap_scores.append(ap)\n",
    "        \n",
    "        return np.mean(ap_scores) if ap_scores else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8be54825-71df-4158-bd7d-e12b73f8fd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded: 57555 books\n",
      "Building TF-IDF index...\n",
      "Training Learning to Rank model...\n",
      "Learning to Rank model trained!\n",
      "\n",
      "============================================================\n",
      "BOOK SEARCH ENGINE WITH LEARNING TO RANK\n",
      "============================================================\n",
      "\n",
      "Masukkan query (atau 'quit' untuk keluar):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  love of my life\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hasil pencarian untuk: 'love of my life'\n",
      "--------------------------------------------------\n",
      "1. The Haunter of the Dark: The H.P. Lovecraft Omnibus, #3\n",
      "   Author: H.P. Lovecraft, August Derleth (Introduction)\n",
      "   Score: 2.0000\n",
      "   Description: WARNING! YOU ARE ABOUT TO ENTER A NEW DIMENSION OF UTMOST TERRORWhen you open this book you will lost - lost in a world of dreadful nightmare brought to screaming life by the century's greatest master...\n",
      "   ISBN: 9780586063231\n",
      "\n",
      "2. Dreams of My Russian Summers\n",
      "   Author: Andreï Makine, Geoffrey Strachan (Translator)\n",
      "   Score: 2.0000\n",
      "   Description: Dreams of My Russian Summers, tells the poignant story of a boy growing up amid the harsh realities of Soviet life in the 1960s and '70s, and of his extraordinary love for an elegant Frenchwoman, Char...\n",
      "   ISBN: 9780684852683\n",
      "\n",
      "3. The Art of Amy Brown\n",
      "   Author: Amy Brown (Annotations), Charles de Lint (Goodreads Author) (Introduction)\n",
      "   Score: 2.0000\n",
      "   Description: The Art of Amy Brown is the first collection of Amy Brown's wildly popular art. It was published by Chimera Publishing in 2003. The book is 157 pages of art, with a commentary by Amy Brown for every p...\n",
      "   ISBN: 9780974461229\n",
      "\n",
      "4. Everybody, Always: Becoming Love in a World Full of Setbacks and Difficult People\n",
      "   Author: Bob Goff\n",
      "   Score: 2.0000\n",
      "   Description: New York Times Bestseller!What happens when we give away love like we're made of it? In his entertaining and inspiring follow-up to the New York Times bestselling phenomenon Love Does, Bob Goff takes ...\n",
      "   ISBN: 9780718078133\n",
      "\n",
      "5. Sky Burial: An Epic Love Story of Tibet\n",
      "   Author: Xinran, Julia Lovell (Translator), Esther Tyldesley (Translator)\n",
      "   Score: 2.0000\n",
      "   Description: It was 1994 when Xinran, a journalist and the author of The Good Women of China, received a telephone call asking her to travel four hours to meet an oddly dressed woman who had just crossed the borde...\n",
      "   ISBN: 9780385515481\n",
      "\n",
      "6. Nobody Can Love You More: Life in Delhi's Red Light District\n",
      "   Author: Mayank Soofi\n",
      "   Score: 2.0000\n",
      "   Description: The sex workers of Kotha No. 300 raise their children, cook for their lovers, visit temples, shrines and mosques, complain about pimps and brothel owners, listen to film songs, and solicit and enterta...\n",
      "   ISBN: 9780670084142\n",
      "\n",
      "7. The Best of H.P. Lovecraft: Bloodcurdling Tales of Horror and the Macabre\n",
      "   Author: H.P. Lovecraft, August Derleth (Editor), Robert Bloch (Introduction)\n",
      "   Score: 2.0000\n",
      "   Description: “H.P. Lovecraft has yet to be surpassed as the twentieth century’s greatest practitioner of the classic horror tale.”—Stephen King“The oldest and strongest emotion of mankind is fear, and the oldest a...\n",
      "   ISBN: 9780345350800\n",
      "\n",
      "8. Tales of H.P. Lovecraft\n",
      "   Author: H.P. Lovecraft, Joyce Carol Oates (Editor)\n",
      "   Score: 2.0000\n",
      "   Description: When he died in 1937, destitute and emotionally and physically ruined.  H.P. Lovecraft had no idea that he would come to be regarded as the godfather of the modern horror genre, nor that his work woul...\n",
      "   ISBN: 9780060957902\n",
      "\n",
      "9. The Transition of H. P. Lovecraft: The Road to Madness\n",
      "   Author: H.P. Lovecraft, Barbara Hambly (Goodreads Author) (introduction)\n",
      "   Score: 2.0000\n",
      "   Description: One of the most influential practitioners of American horror, H.P. Lovecraft inspired the work of Stephen King, Anne Rice, and Clive Barker. As he perfected his mastery of the macabre, his works devel...\n",
      "   ISBN: 9780345384225\n",
      "\n",
      "10. The Tao of Physics: An Exploration of the Parallels between Modern Physics and Eastern Mysticism\n",
      "   Author: Fritjof Capra\n",
      "   Score: 2.0000\n",
      "   Description: After a quarter of a century in print, Capra's groundbreaking work still challenges and inspires. This updated edition of The Tao of Physics  includes a new preface and afterword in which the author r...\n",
      "   ISBN: 9781570625190\n",
      "\n",
      "\n",
      "EVALUASI METRICS:\n",
      "------------------------------\n",
      "Precision@5: 0.6000\n",
      "Recall@5: 1.0000\n",
      "MAP@5: 1.0000\n",
      "NDCG@5: 1.0000\n",
      "Batch MAP@5: 1.0000\n",
      "\n",
      "Masukkan query (atau 'quit' untuk keluar):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  quit\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function untuk menjalankan sistem\n",
    "    \"\"\"\n",
    "    # Path dataset\n",
    "    csv_path = \"D:/IT DEL/Semester 8 (FINAL)/STBI/Information-Retrieval-Books-search-engine-main/Information-Retrieval-Books-search-engine-main/data_books_updated.csv\"\n",
    "    \n",
    "    # Initialize search engine\n",
    "    search_engine = BookSearchEngine(csv_path)\n",
    "    \n",
    "    try:\n",
    "        # Load dan preprocess data\n",
    "        search_engine.load_data()\n",
    "        \n",
    "        # Build indices\n",
    "        search_engine.build_tfidf_index()\n",
    "        \n",
    "        # Train Learning to Rank model\n",
    "        search_engine.train_learning_to_rank_model()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"BOOK SEARCH ENGINE WITH LEARNING TO RANK\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Interactive search\n",
    "        while True:\n",
    "            print(\"\\nMasukkan query (atau 'quit' untuk keluar):\")\n",
    "            query = input(\"Query: \").strip()\n",
    "            \n",
    "            if query.lower() in ['quit', 'exit', 'q']:\n",
    "                break\n",
    "            \n",
    "            if not query:\n",
    "                continue\n",
    "            \n",
    "            # Perform search\n",
    "            results = search_engine.search(query, top_k=10)\n",
    "            \n",
    "            print(f\"\\nHasil pencarian untuk: '{query}'\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            if len(results) == 0:\n",
    "                print(\"Tidak ada hasil yang ditemukan.\")\n",
    "                continue\n",
    "            \n",
    "            for result in results:\n",
    "                print(f\"{result['rank']}. {result['title']}\")\n",
    "                print(f\"   Author: {result['author']}\")\n",
    "                print(f\"   Score: {result['score']:.4f}\")\n",
    "                print(f\"   Description: {result['description']}\")\n",
    "                print(f\"   ISBN: {result['isbn']}\")\n",
    "                print()\n",
    "            \n",
    "            # Simulasi evaluasi (dengan synthetic ground truth)\n",
    "            # Dalam implementasi nyata, ground truth akan disediakan secara manual\n",
    "            print(\"\\nEVALUASI METRICS:\")\n",
    "            print(\"-\" * 30)\n",
    "            \n",
    "            # Generate synthetic relevant items (top 3 results sebagai relevant)\n",
    "            relevant_items = [str(r['isbn']) for r in results[:3]]\n",
    "            retrieved_items = [str(r['isbn']) for r in results]\n",
    "            \n",
    "            # Calculate metrics\n",
    "            precision_5 = EvaluationMetrics.precision_at_k(relevant_items, retrieved_items, 5)\n",
    "            recall_5 = EvaluationMetrics.recall_at_k(relevant_items, retrieved_items, 5)\n",
    "            ap_5 = EvaluationMetrics.average_precision_at_k(relevant_items, retrieved_items, 5)\n",
    "            ndcg_5 = EvaluationMetrics.ndcg_at_k(relevant_items, retrieved_items, 5)\n",
    "            \n",
    "            print(f\"Precision@5: {precision_5:.4f}\")\n",
    "            print(f\"Recall@5: {recall_5:.4f}\")\n",
    "            print(f\"MAP@5: {ap_5:.4f}\")\n",
    "            print(f\"NDCG@5: {ndcg_5:.4f}\")\n",
    "            \n",
    "            # Contoh evaluasi batch untuk MAP@5\n",
    "            queries_results = [(relevant_items, retrieved_items)]\n",
    "            map_5 = EvaluationMetrics.map_at_k(queries_results, 5)\n",
    "            print(f\"Batch MAP@5: {map_5:.4f}\")\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File tidak ditemukan di path: {csv_path}\")\n",
    "        print(\"Pastikan path file sudah benar!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0429204-bfae-4884-99f8-a01522312c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
