{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81dbbc24-56a8-4e79-a9eb-c0a5baff9051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import string\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eacf0720-13e9-43c0-9051-8310190480f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocchioInformationRetrieval:\n",
    "    def __init__(self, csv_path, alpha=1.0, beta=0.75, gamma=0.15):\n",
    "        \"\"\"\n",
    "        Initialize Rocchio Information Retrieval System\n",
    "        \n",
    "        Parameters:\n",
    "        - csv_path: path to the CSV file\n",
    "        - alpha: weight for original query (default: 1.0)\n",
    "        - beta: weight for relevant documents (default: 0.75)\n",
    "        - gamma: weight for non-relevant documents (default: 0.15)\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # Load and preprocess data\n",
    "        self.df = self.load_data()\n",
    "        self.documents = self.preprocess_documents()\n",
    "        \n",
    "        # Initialize TF-IDF vectorizer\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            max_features=5000,\n",
    "            stop_words='english',\n",
    "            lowercase=True,\n",
    "            ngram_range=(1, 2)\n",
    "        )\n",
    "        \n",
    "        # Fit vectorizer on documents\n",
    "        self.doc_vectors = self.vectorizer.fit_transform(self.documents)\n",
    "        \n",
    "        print(f\"Loaded {len(self.df)} documents\")\n",
    "        print(f\"TF-IDF matrix shape: {self.doc_vectors.shape}\")\n",
    "    \n",
    "    def load_data(self):\n",
    "        \"\"\"Load CSV data\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(self.csv_path)\n",
    "            # Handle missing values\n",
    "            df['Book-Title'] = df['Book-Title'].fillna('')\n",
    "            df['Book-Author'] = df['Book-Author'].fillna('')\n",
    "            df['description'] = df['description'].fillna('')\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Preprocess text: lowercase, remove punctuation, etc.\"\"\"\n",
    "        if pd.isna(text) or text == '':\n",
    "            return ''\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = str(text).lower()\n",
    "        \n",
    "        # Remove punctuation\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def preprocess_documents(self):\n",
    "        \"\"\"Combine and preprocess document fields\"\"\"\n",
    "        documents = []\n",
    "        for idx, row in self.df.iterrows():\n",
    "            # Combine title, author, and description\n",
    "            combined_text = f\"{row['Book-Title']} {row['Book-Author']} {row['description']}\"\n",
    "            processed_text = self.preprocess_text(combined_text)\n",
    "            documents.append(processed_text)\n",
    "        \n",
    "        return documents\n",
    "    \n",
    "    def search(self, query, top_k=10):\n",
    "        \"\"\"Initial search without relevance feedback\"\"\"\n",
    "        # Preprocess query\n",
    "        processed_query = self.preprocess_text(query)\n",
    "        \n",
    "        # Transform query to TF-IDF vector\n",
    "        query_vector = self.vectorizer.transform([processed_query])\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        similarities = cosine_similarity(query_vector, self.doc_vectors).flatten()\n",
    "        \n",
    "        # Get top-k results\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            results.append({\n",
    "                'index': idx,\n",
    "                'title': self.df.iloc[idx]['Book-Title'],\n",
    "                'author': self.df.iloc[idx]['Book-Author'],\n",
    "                'description': self.df.iloc[idx]['description'][:200] + '...' if len(str(self.df.iloc[idx]['description'])) > 200 else self.df.iloc[idx]['description'],\n",
    "                'score': similarities[idx]\n",
    "            })\n",
    "        \n",
    "        return results, query_vector\n",
    "    \n",
    "    def rocchio_feedback(self, original_query_vector, relevant_docs, non_relevant_docs):\n",
    "        \"\"\"Apply Rocchio algorithm for query expansion\"\"\"\n",
    "        \n",
    "        # Start with original query\n",
    "        new_query_vector = self.alpha * original_query_vector\n",
    "        \n",
    "        # Add relevant documents\n",
    "        if relevant_docs:\n",
    "            relevant_vectors = self.doc_vectors[relevant_docs]\n",
    "            centroid_relevant = np.mean(relevant_vectors, axis=0)\n",
    "            new_query_vector += self.beta * centroid_relevant\n",
    "        \n",
    "        # Subtract non-relevant documents\n",
    "        if non_relevant_docs:\n",
    "            non_relevant_vectors = self.doc_vectors[non_relevant_docs]\n",
    "            centroid_non_relevant = np.mean(non_relevant_vectors, axis=0)\n",
    "            new_query_vector -= self.gamma * centroid_non_relevant\n",
    "        \n",
    "        return new_query_vector\n",
    "    \n",
    "    def search_with_feedback(self, query, relevant_docs=None, non_relevant_docs=None, top_k=10):\n",
    "        \"\"\"Search with Rocchio relevance feedback\"\"\"\n",
    "        # Initial search\n",
    "        initial_results, original_query_vector = self.search(query, top_k)\n",
    "        \n",
    "        # If no feedback provided, return initial results\n",
    "        if not relevant_docs and not non_relevant_docs:\n",
    "            return initial_results\n",
    "        \n",
    "        # Apply Rocchio feedback\n",
    "        new_query_vector = self.rocchio_feedback(\n",
    "            original_query_vector, \n",
    "            relevant_docs, \n",
    "            non_relevant_docs\n",
    "        )\n",
    "        \n",
    "        # Calculate similarities with new query vector\n",
    "        similarities = cosine_similarity(new_query_vector, self.doc_vectors).flatten()\n",
    "        \n",
    "        # Get top-k results\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            results.append({\n",
    "                'index': idx,\n",
    "                'title': self.df.iloc[idx]['Book-Title'],\n",
    "                'author': self.df.iloc[idx]['Book-Author'],\n",
    "                'description': self.df.iloc[idx]['description'][:200] + '...' if len(str(self.df.iloc[idx]['description'])) > 200 else self.df.iloc[idx]['description'],\n",
    "                'score': similarities[idx]\n",
    "            })\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9d735c3-6090-4846-882e-fac10b12e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationMetrics:\n",
    "    \"\"\"Class untuk menghitung evaluation metrics\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def precision_at_k(retrieved_docs, relevant_docs, k=5):\n",
    "        \"\"\"Calculate Precision@K\"\"\"\n",
    "        if k == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        retrieved_k = retrieved_docs[:k]\n",
    "        relevant_retrieved = len(set(retrieved_k) & set(relevant_docs))\n",
    "        return relevant_retrieved / k\n",
    "    \n",
    "    @staticmethod\n",
    "    def recall_at_k(retrieved_docs, relevant_docs, k=5):\n",
    "        \"\"\"Calculate Recall@K\"\"\"\n",
    "        if len(relevant_docs) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        retrieved_k = retrieved_docs[:k]\n",
    "        relevant_retrieved = len(set(retrieved_k) & set(relevant_docs))\n",
    "        return relevant_retrieved / len(relevant_docs)\n",
    "    \n",
    "    @staticmethod\n",
    "    def average_precision(retrieved_docs, relevant_docs):\n",
    "        \"\"\"Calculate Average Precision\"\"\"\n",
    "        if len(relevant_docs) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        precision_scores = []\n",
    "        relevant_count = 0\n",
    "        \n",
    "        for i, doc in enumerate(retrieved_docs):\n",
    "            if doc in relevant_docs:\n",
    "                relevant_count += 1\n",
    "                precision_at_i = relevant_count / (i + 1)\n",
    "                precision_scores.append(precision_at_i)\n",
    "        \n",
    "        if precision_scores:\n",
    "            return sum(precision_scores) / len(relevant_docs)\n",
    "        return 0.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def map_at_k(queries_results, k=5):\n",
    "        \"\"\"Calculate Mean Average Precision@K\"\"\"\n",
    "        if not queries_results:\n",
    "            return 0.0\n",
    "        \n",
    "        ap_scores = []\n",
    "        for retrieved_docs, relevant_docs in queries_results:\n",
    "            retrieved_k = retrieved_docs[:k]\n",
    "            ap = EvaluationMetrics.average_precision(retrieved_k, relevant_docs)\n",
    "            ap_scores.append(ap)\n",
    "        \n",
    "        return sum(ap_scores) / len(ap_scores)\n",
    "    \n",
    "    @staticmethod\n",
    "    def dcg_at_k(retrieved_docs, relevant_docs, k=5):\n",
    "        \"\"\"Calculate Discounted Cumulative Gain@K\"\"\"\n",
    "        dcg = 0.0\n",
    "        for i, doc in enumerate(retrieved_docs[:k]):\n",
    "            if doc in relevant_docs:\n",
    "                # Assuming binary relevance (1 if relevant, 0 if not)\n",
    "                dcg += 1.0 / np.log2(i + 2)  # i+2 because log2(1) = 0\n",
    "        return dcg\n",
    "    \n",
    "    @staticmethod\n",
    "    def ndcg_at_k(retrieved_docs, relevant_docs, k=5):\n",
    "        \"\"\"Calculate Normalized Discounted Cumulative Gain@K\"\"\"\n",
    "        if len(relevant_docs) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Calculate DCG\n",
    "        dcg = EvaluationMetrics.dcg_at_k(retrieved_docs, relevant_docs, k)\n",
    "        \n",
    "        # Calculate IDCG (Ideal DCG)\n",
    "        ideal_retrieved = relevant_docs[:k]  # Best possible ranking\n",
    "        idcg = EvaluationMetrics.dcg_at_k(ideal_retrieved, relevant_docs, k)\n",
    "        \n",
    "        if idcg == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return dcg / idcg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e11e08-9b22-4b4f-a659-8bd5b9825b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Information Retrieval System...\n",
      "Loaded 58477 documents\n",
      "TF-IDF matrix shape: (58477, 5000)\n",
      "\n",
      "============================================================\n",
      "INFORMATION RETRIEVAL SYSTEM WITH ROCCHIO ALGORITHM\n",
      "============================================================\n",
      "\n",
      "Options:\n",
      "1. Search without feedback\n",
      "2. Search with relevance feedback\n",
      "3. Evaluate system performance\n",
      "4. Exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Select option (1-4):  1\n",
      "\n",
      "Enter your search query:  love of my life\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching for: 'love of my life'\n",
      "\n",
      "Top 10 Results:\n",
      "--------------------------------------------------------------------------------\n",
      "1. Title: Love Life\n",
      "   Author: Rob Lowe\n",
      "   Score: 0.5785\n",
      "   Description: Rob Lowe is back with stories he only tells his best friends.When Rob Lowe's first book was published in 2011, he received the kind of rapturous reviews that writers dream of and rocketed to the top o...\n",
      "--------------------------------------------------------------------------------\n",
      "2. Title: Chris-In-The-Morning: Love, Life, and the Whole Karmic Enchilada\n",
      "   Author: Louis Chunovic\n",
      "   Score: 0.5243\n",
      "   Description: Chris-In-The-Morning is a book about love, life, and the whole karmic enchilada. It's about a man named Chris who is struggling with his relationships and his career. He's trying to figure out what he...\n",
      "--------------------------------------------------------------------------------\n",
      "3. Title: Expressions of Faith: Inspirational Stories of Life and Love\n",
      "   Author: Guideposts Magazine\n",
      "   Score: 0.4261\n",
      "   Description: A collection of stories about faith, love, and life.\n",
      "--------------------------------------------------------------------------------\n",
      "4. Title: You, My Love: A Diary in Verse\n",
      "   Author: Richard Atwood (Goodreads Author)\n",
      "   Score: 0.4089\n",
      "   Description: 13 January You are into melike flame and fireas no other desire couldknow such gentle fury ...like an undefined thirstincalculably uncontrolled,or passion spent in seekinga wild         and wondrous r...\n",
      "--------------------------------------------------------------------------------\n",
      "5. Title: Love Your Life: Living Happy, Healthy and Whole\n",
      "   Author: Victoria Osteen\n",
      "   Score: 0.4049\n",
      "   Description: Do you ever feel like your life is moving at the speed of light? Are you constantly trying to keep up with all of your commitments and responsibilities? In this day and age when modern communication a...\n",
      "--------------------------------------------------------------------------------\n",
      "6. Title: 愛しのチロ (Chiro, My Love)\n",
      "   Author: Nobuyoshi Araki, 荒木 経惟\n",
      "   Score: 0.3860\n",
      "   Description: \n",
      "--------------------------------------------------------------------------------\n",
      "7. Title: A Fire That Burns\n",
      "   Author: Kirsty-Anne Still (Goodreads Author)\n",
      "   Score: 0.3817\n",
      "   Description: “Six years on and you’re still as in love with me as you were when you left. You never stopped loving me, you never could. You didn’t leave because you didn’t love me.”After running from the truth for...\n",
      "--------------------------------------------------------------------------------\n",
      "8. Title: I Too Had a Love Story\n",
      "   Author: Ravinder Singh\n",
      "   Score: 0.3787\n",
      "   Description: Do love stories ever die?. . . How would you react when a beautiful person comes into your life, and then goes away from you . . . forever?Not all love stories are meant to have a perfect ending. I To...\n",
      "--------------------------------------------------------------------------------\n",
      "9. Title: Set-Up the Story of Trinity\n",
      "   Author: Desiree Cochran\n",
      "   Score: 0.3771\n",
      "   Description: This is the story of Trinity Danell, a young mother, desperately trying to fit in. All she wants is the love of her life, but everything stands in her way. Murder, mystery, lies, betrayal and being se...\n",
      "--------------------------------------------------------------------------------\n",
      "10. Title: Nothing Like the Sun\n",
      "   Author: Anthony Burgess\n",
      "   Score: 0.3581\n",
      "   Description: Before Shakespeare in Love, there was Anthony Burgess's Nothing Like the Sun: a magnificent, bawdy telling of Shakespeare's love life.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Options:\n",
      "1. Search without feedback\n",
      "2. Search with relevance feedback\n",
      "3. Evaluate system performance\n",
      "4. Exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Select option (1-4):  2\n",
      "\n",
      "Enter your search query:  love of my life\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial search for: 'love of my life'\n",
      "\n",
      "Initial Top 10 Results:\n",
      "--------------------------------------------------------------------------------\n",
      "1. Title: Love Life\n",
      "   Author: Rob Lowe\n",
      "   Score: 0.5785\n",
      "--------------------------------------------------------------------------------\n",
      "2. Title: Chris-In-The-Morning: Love, Life, and the Whole Karmic Enchilada\n",
      "   Author: Louis Chunovic\n",
      "   Score: 0.5243\n",
      "--------------------------------------------------------------------------------\n",
      "3. Title: Expressions of Faith: Inspirational Stories of Life and Love\n",
      "   Author: Guideposts Magazine\n",
      "   Score: 0.4261\n",
      "--------------------------------------------------------------------------------\n",
      "4. Title: You, My Love: A Diary in Verse\n",
      "   Author: Richard Atwood (Goodreads Author)\n",
      "   Score: 0.4089\n",
      "--------------------------------------------------------------------------------\n",
      "5. Title: Love Your Life: Living Happy, Healthy and Whole\n",
      "   Author: Victoria Osteen\n",
      "   Score: 0.4049\n",
      "--------------------------------------------------------------------------------\n",
      "6. Title: 愛しのチロ (Chiro, My Love)\n",
      "   Author: Nobuyoshi Araki, 荒木 経惟\n",
      "   Score: 0.3860\n",
      "--------------------------------------------------------------------------------\n",
      "7. Title: A Fire That Burns\n",
      "   Author: Kirsty-Anne Still (Goodreads Author)\n",
      "   Score: 0.3817\n",
      "--------------------------------------------------------------------------------\n",
      "8. Title: I Too Had a Love Story\n",
      "   Author: Ravinder Singh\n",
      "   Score: 0.3787\n",
      "--------------------------------------------------------------------------------\n",
      "9. Title: Set-Up the Story of Trinity\n",
      "   Author: Desiree Cochran\n",
      "   Score: 0.3771\n",
      "--------------------------------------------------------------------------------\n",
      "10. Title: Nothing Like the Sun\n",
      "   Author: Anthony Burgess\n",
      "   Score: 0.3581\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Provide relevance feedback:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter relevant document numbers (comma-separated, e.g., 1,3,5):  1000\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Path ke dataset\n",
    "    csv_path = \"D:/IT DEL/Semester 8 (FINAL)/STBI/Information-Retrieval-Books-search-engine-main/Information-Retrieval-Books-search-engine-main/data_books_updated.csv\"\n",
    "    \n",
    "    # Initialize IR system\n",
    "    print(\"Initializing Information Retrieval System...\")\n",
    "    ir_system = RocchioInformationRetrieval(csv_path)\n",
    "    \n",
    "    if ir_system.df is None:\n",
    "        print(\"Failed to load data. Please check the file path.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"INFORMATION RETRIEVAL SYSTEM WITH ROCCHIO ALGORITHM\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\nOptions:\")\n",
    "        print(\"1. Search without feedback\")\n",
    "        print(\"2. Search with relevance feedback\") \n",
    "        print(\"3. Evaluate system performance\")\n",
    "        print(\"4. Exit\")\n",
    "        \n",
    "        choice = input(\"\\nSelect option (1-4): \").strip()\n",
    "        \n",
    "        if choice == '1':\n",
    "            # Search without feedback\n",
    "            query = input(\"\\nEnter your search query: \").strip()\n",
    "            if not query:\n",
    "                print(\"Please enter a valid query.\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"\\nSearching for: '{query}'\")\n",
    "            results, _ = ir_system.search(query, top_k=10)\n",
    "            \n",
    "            print(f\"\\nTop 10 Results:\")\n",
    "            print(\"-\" * 80)\n",
    "            for i, result in enumerate(results, 1):\n",
    "                print(f\"{i}. Title: {result['title']}\")\n",
    "                print(f\"   Author: {result['author']}\")\n",
    "                print(f\"   Score: {result['score']:.4f}\")\n",
    "                print(f\"   Description: {result['description']}\")\n",
    "                print(\"-\" * 80)\n",
    "        \n",
    "        elif choice == '2':\n",
    "            # Search with relevance feedback\n",
    "            query = input(\"\\nEnter your search query: \").strip()\n",
    "            if not query:\n",
    "                print(\"Please enter a valid query.\")\n",
    "                continue\n",
    "            \n",
    "            # Initial search\n",
    "            print(f\"\\nInitial search for: '{query}'\")\n",
    "            initial_results, _ = ir_system.search(query, top_k=10)\n",
    "            \n",
    "            print(f\"\\nInitial Top 10 Results:\")\n",
    "            print(\"-\" * 80)\n",
    "            for i, result in enumerate(initial_results, 1):\n",
    "                print(f\"{i}. Title: {result['title']}\")\n",
    "                print(f\"   Author: {result['author']}\")\n",
    "                print(f\"   Score: {result['score']:.4f}\")\n",
    "                print(\"-\" * 80)\n",
    "            \n",
    "            # Get relevance feedback\n",
    "            print(\"\\nProvide relevance feedback:\")\n",
    "            relevant_input = input(\"Enter relevant document numbers (comma-separated, e.g., 1,3,5): \").strip()\n",
    "            non_relevant_input = input(\"Enter non-relevant document numbers (comma-separated, e.g., 2,4): \").strip()\n",
    "            \n",
    "            relevant_docs = []\n",
    "            non_relevant_docs = []\n",
    "            \n",
    "            # Parse relevant documents\n",
    "            if relevant_input:\n",
    "                try:\n",
    "                    relevant_nums = [int(x.strip()) for x in relevant_input.split(',')]\n",
    "                    relevant_docs = [initial_results[i-1]['index'] for i in relevant_nums if 1 <= i <= len(initial_results)]\n",
    "                except:\n",
    "                    print(\"Invalid input for relevant documents.\")\n",
    "            \n",
    "            # Parse non-relevant documents  \n",
    "            if non_relevant_input:\n",
    "                try:\n",
    "                    non_relevant_nums = [int(x.strip()) for x in non_relevant_input.split(',')]\n",
    "                    non_relevant_docs = [initial_results[i-1]['index'] for i in non_relevant_nums if 1 <= i <= len(initial_results)]\n",
    "                except:\n",
    "                    print(\"Invalid input for non-relevant documents.\")\n",
    "            \n",
    "            # Search with feedback\n",
    "            if relevant_docs or non_relevant_docs:\n",
    "                print(f\"\\nApplying Rocchio feedback...\")\n",
    "                feedback_results = ir_system.search_with_feedback(\n",
    "                    query, relevant_docs, non_relevant_docs, top_k=10\n",
    "                )\n",
    "                \n",
    "                print(f\"\\nResults after Rocchio feedback:\")\n",
    "                print(\"-\" * 80)\n",
    "                for i, result in enumerate(feedback_results, 1):\n",
    "                    print(f\"{i}. Title: {result['title']}\")\n",
    "                    print(f\"   Author: {result['author']}\")\n",
    "                    print(f\"   Score: {result['score']:.4f}\")\n",
    "                    print(\"-\" * 80)\n",
    "            else:\n",
    "                print(\"No feedback provided.\")\n",
    "        \n",
    "        elif choice == '3':\n",
    "            # Evaluate system performance\n",
    "            print(\"\\nEvaluating system performance...\")\n",
    "            print(\"Note: This is a demo evaluation with sample queries.\")\n",
    "            \n",
    "            # Sample queries untuk evaluasi\n",
    "            sample_queries = [\n",
    "                (\"python programming\", [100, 150, 200]),  # Sample relevant doc indices\n",
    "                (\"machine learning\", [50, 75, 125]),\n",
    "                (\"data science\", [25, 175, 225])\n",
    "            ]\n",
    "            \n",
    "            metrics = EvaluationMetrics()\n",
    "            queries_results = []\n",
    "            \n",
    "            for query, relevant_docs in sample_queries:\n",
    "                results, _ = ir_system.search(query, top_k=10)\n",
    "                retrieved_docs = [r['index'] for r in results]\n",
    "                queries_results.append((retrieved_docs, relevant_docs))\n",
    "            \n",
    "            # Calculate metrics\n",
    "            map_5 = metrics.map_at_k(queries_results, k=5)\n",
    "            \n",
    "            # Calculate average metrics across queries\n",
    "            precision_scores = []\n",
    "            recall_scores = []\n",
    "            ndcg_scores = []\n",
    "            \n",
    "            for retrieved_docs, relevant_docs in queries_results:\n",
    "                precision_scores.append(metrics.precision_at_k(retrieved_docs, relevant_docs, k=5))\n",
    "                recall_scores.append(metrics.recall_at_k(retrieved_docs, relevant_docs, k=5))\n",
    "                ndcg_scores.append(metrics.ndcg_at_k(retrieved_docs, relevant_docs, k=5))\n",
    "            \n",
    "            avg_precision = sum(precision_scores) / len(precision_scores)\n",
    "            avg_recall = sum(recall_scores) / len(recall_scores)\n",
    "            avg_ndcg = sum(ndcg_scores) / len(ndcg_scores)\n",
    "            \n",
    "            print(f\"\\nEvaluation Results:\")\n",
    "            print(\"-\" * 40)\n",
    "            print(f\"MAP@5:        {map_5:.4f}\")\n",
    "            print(f\"NDCG@5:       {avg_ndcg:.4f}\")\n",
    "            print(f\"Precision@5:  {avg_precision:.4f}\")\n",
    "            print(f\"Recall@5:     {avg_recall:.4f}\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "        elif choice == '4':\n",
    "            print(\"\\nThank you for using the Information Retrieval System!\")\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            print(\"Invalid option. Please select 1-4.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23463907-a525-4601-a686-6afca3a9be01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
